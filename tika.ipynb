{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d3ea607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tika in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from tika) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from tika) (69.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from requests->tika) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from requests->tika) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from requests->tika) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages (from requests->tika) (2.10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\karim aboelazm\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40ab4eee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Microsoft Word - Basic Curriculum Vitae example.doc\n",
      "\n",
      "\n",
      "Basic Curriculum Vitae Example \n",
      "\n",
      "Curriculum Vitae  ‐   Donald Sunter \n",
      " \n",
      "\n",
      "P.O. Box 2526 ∙ Polokwane ∙ 2069 ∙ 073 555 9897 ∙ dsunter@onetwo.co.za \n",
      " \n",
      "\n",
      "Personal details \n",
      " \n",
      "ID number:              891211 5586 225 \n",
      "Date of birth:          11 December 1989 \n",
      "Nationality:             SA Citizen \n",
      "Languages:              English, Tswana, Afrikaans \n",
      "Driver’s license:     Yes Code 10 \n",
      " \n",
      "\n",
      "Objective \n",
      " \n",
      "An objective gives focus to your CV – the reader will know immediately what you are looking for and \n",
      "if you are a good candidate for the advertised position. \n",
      " \n",
      "\n",
      "Educational Background \n",
      " \n",
      "Tertiary education: \n",
      " \n",
      "Institution                            Degree                                Date of completion \n",
      "Subjects: \n",
      " \n",
      "Institution                            Degree                                Date of completion \n",
      "Subjects: \n",
      " \n",
      "Secondary education: \n",
      " \n",
      "School                                   Grade                                  Date of completion \n",
      "Subjects: \n",
      " \n",
      "\n",
      "Relevant experience \n",
      " \n",
      "Work experience \n",
      " \n",
      "                       Job Title                                                Month/Year – Month/Year \n",
      "                       Recent Employer Name, City, Province \n",
      "\n",
      "• List your most relevant accomplishment for this job. \n",
      "• Another accomplishment which is related to the target job qualifications. \n",
      "• Name a skill perfected and required for the target job. \n",
      "\n",
      " \n",
      "                       Job Title                                                Month/Year – Month/Year \n",
      "                       Employer Name, City, Province \n",
      "\n",
      "• State a global summary of the scope of the job and add your proudest \n",
      "accomplishment as it relates to the target job. \n",
      "\n",
      "• State another accomplishment which is relevant to the qualifications needed \n",
      "for the target job. \n",
      "\n",
      "• Name a skill perfected and required for the target job. \n",
      "\n",
      "Your address could \n",
      "also be in table \n",
      "\n",
      "format underneath \n",
      "your name and \n",
      "\n",
      "surname. \n",
      "\n",
      "Font should be easy to \n",
      "read, size should be \n",
      "between 10 and 12. \n",
      "Avoid colour. \n",
      "\n",
      "Make sure you include \n",
      "the institution, degree, \n",
      "date of completion and \n",
      "main subjects. Start with \n",
      "the most recent \n",
      "qualification. It might not \n",
      "be necessary to include \n",
      "the school subjects. The \n",
      "older you are, the less \n",
      "important your school \n",
      "information will become. \n",
      "\n",
      "Highlight briefly \n",
      "how your skills \n",
      "and abilities fit \n",
      "the vacancy. \n",
      "Organise your \n",
      "experiences in \n",
      "categories. \n",
      "\n",
      "Your email address \n",
      "should be professional.  \n",
      "Avoid nicknames. \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "Leadership experience \n",
      " \n",
      "\n",
      "• List activities where leadership has been developed. \n",
      "                          \n",
      "Computer skills \n",
      " \n",
      "\n",
      "• Microsoft Office, Adobe PageMaker, Adobe Illustrator, Adobe Photoshop, \n",
      "Dreamweaver, Unix, Linux, Oracle. \n",
      "\n",
      " \n",
      "Community involvement \n",
      " \n",
      "\n",
      "• List all relevant community projects. \n",
      " \n",
      "\n",
      "Conference Papers (If applicable) \n",
      " \n",
      "It is absolutely vital that you separate conference papers and presentations from published works. If \n",
      "you have only given a few of each type of paper, it may be better to group them together. Use your \n",
      "judgment. \n",
      " \n",
      "\n",
      "Publications (If applicable) \n",
      " \n",
      "This section typically appears near the end of the CV, followed only by the list of references. \n",
      " \n",
      "\n",
      "Interests \n",
      " \n",
      "\n",
      "• Enjoy reading traveling magazines. \n",
      "• Avid wildlife  photographer with  the  goal  of writing  and  photographing  travel \n",
      "\n",
      "destinations. \n",
      "• Participate in outdoor activities, including hiking, canoeing, backpacking and \n",
      "\n",
      "skiing. \n",
      " \n",
      "\n",
      "References \n",
      " \n",
      "A list of 3 people who are providing the reference letters that accompany your application. Always \n",
      "ask an individual to be a reference for you prior to mentioning his/her name to prospective \n",
      "employers. Prepare a list of three references to provide at the interview. This list should include \n",
      "name, title, employer, address, telephone number and e‐mail address. \n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Demonstrate that you \n",
      "understand the nature of \n",
      "the job being advertised \n",
      "and explain why you \n",
      "want to work in that \n",
      "area. \n",
      "\n",
      "Ensure that your CV is \n",
      "well spaced and visually \n",
      "attractive. \n",
      "\n",
      "Be concise. Continue \n",
      "revising and fine‐tuning \n",
      "your resume. Proofread! \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tika import parser\n",
    "file = r'123.pdf'\n",
    "file_data = parser.from_file(file)\n",
    "text = file_data['content']\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc76141b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "section_pattern = re.compile(r'^\\s*(\\w+)\\s*$', re.MULTILINE)\n",
    "\n",
    "# Find all section titles\n",
    "sections = section_pattern.finditer(text)\n",
    "\n",
    "# Initialize variables to store skills section\n",
    "skills_section = \"\"\n",
    "\n",
    "# Iterate through sections to find \"SKILLS\" section\n",
    "for match in sections:\n",
    "    if match.group(1) in [\"SKILLS\",\"skills\"]:\n",
    "#         # Extract lines until the next section title appears\n",
    "        skills_section = text[match.end():sections.__next__().end()+115]\n",
    "\n",
    "all_skills = skills_section.strip()\n",
    "all_skills = all_skills.split('\\n')\n",
    "for skill in all_skills:\n",
    "    if skill == '':\n",
    "        all_skills.remove(skill)\n",
    "converted_skills = []\n",
    "\n",
    "for skill in all_skills:\n",
    "    if '/' in skill:\n",
    "        sub_skills = [s.strip() for s in skill.split('/')]\n",
    "        converted_skills.extend(sub_skills)\n",
    "    else:\n",
    "        converted_skills.append(skill.strip())\n",
    "\n",
    "print(converted_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc36bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['karimaboelazm6@gmail.com', '20912017100480@fci.zu.edu.eg']\n"
     ]
    }
   ],
   "source": [
    "parsed_content = {}\n",
    "import re\n",
    "def get_email_addresses(string):\n",
    "    r = re.compile(r'[\\w\\.-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', re.UNICODE)\n",
    "    email_list = r.findall(string)\n",
    "    clean_email_list = []\n",
    "    for email in email_list:\n",
    "        correct_email=\"\"\n",
    "        for ch in email:\n",
    "            if ord(ch) < 128:\n",
    "                correct_email += ch\n",
    "        clean_email_list.append(correct_email)\n",
    "    return clean_email_list\n",
    "email = get_email_addresses(text)\n",
    "print(email)\n",
    "parsed_content['E-mail'] = email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cc7f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['+201278789685']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def get_phone_numbers(string):\n",
    "    r = re.compile(r'(\\+\\d{2}\\s*\\d{3}\\s*\\d{3}\\s*\\d{4})')\n",
    "    phone_numbers = r.findall(string)\n",
    "    phone_numbers = [num.replace(\" \", \"\") for num in phone_numbers]\n",
    "    return phone_numbers\n",
    "\n",
    "phone_number= get_phone_numbers(text)\n",
    "if len(phone_number) < 12:\n",
    "    print(phone_number)\n",
    "    parsed_content['Phone number'] = phone_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fca9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Karim Mohammed Aboelazm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "def extract_name(text):\n",
    "    nlp_text = nlp(text)\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}]  \n",
    "    matcher.add('NAME', [pattern], on_match = None)\n",
    "    matches = matcher(nlp_text)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return  str(span.text).title()\n",
    "\n",
    "name = extract_name(text)\n",
    "print(name)\n",
    "parsed_content['Name'] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c899a1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords = [\"education\",\n",
    "            \"summary\",\n",
    "            \"accomplishments\",\n",
    "            \"executive profile\",\n",
    "            \"professional profile\",\n",
    "            \"personal profile\",\n",
    "            \"work background\",\n",
    "            \"academic profile\",\n",
    "            \"other activities\",\n",
    "            \"qualifications\",\n",
    "            \"experience\",\n",
    "            \"interests\",\n",
    "            \"skills\",\n",
    "            \"achievements\",\n",
    "            \"publications\",\n",
    "            \"publication\",\n",
    "            \"certifications\",\n",
    "            \"workshops\",\n",
    "            \"projects\",\n",
    "            \"internships\",\n",
    "            \"trainings\",\n",
    "            \"hobbies\",\n",
    "            \"overview\",\n",
    "            \"objective\",\n",
    "            \"position of responsibility\",\n",
    "            \"jobs\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268a77d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 karim mohammed aboelazm.pdf   karim mohammed aboelazm - python & web developer -  address: mit-rabihah al baydaa, bilbeis, ash sharqia governorate  email: karimaboelazm6@gmail.com / 20912017100480@fci.zu.edu.eg linkedin: https://www.linkedin.com/in/karim-mohamed-aboelazm-3717001b3/ github: https://github.com/karim-aboelazm  phone: +20 127 878 9685  i'm karim mohammed aboelazm. i'm working as python software developer in obour academy. willing to work as a professional software developer in an international programming company like google, microsoft, open ai, or tesla and so on, and using my information technology skills to improve company that i will work in, keeping learning modern information technology and improve my position in company.  2017 — 2021 bs in computer science form, the faculty of computer and informatics, zagazig  university, graduation project: stock market predictor using machine learning. project grade: excellent  e programming languages: python, c++, java , javascript  e al techniques: machine learning, deep learning , computer vision  e al framework: pytorch, scikit-learn, tensorflow.  e database: mysql, oracle, postgres, mongo db  e front-end: html5, css3, bootstrap  e back-end: django, flask  e other technology: os, linux, data structure , algorithms , github , rest-api , aws, microservices  e soft skill: communication, empathy , patience , open-minded , adaptability , critical thinking , creativity , confidence , teamwork and collaboration , eagar to learn , time management , work under pressure , ability to learn quickly and work as a part of team.      1. job board: a website employers use to advertise their available positions to qualified job seekers.  while employees can search for new opportunities, employers can fill vacancies with knowledgeable workers. developed by using python (django).  2. stock market predictor: a machine learning project that act of trying to determine the future value of a company stock or other financial instrument traded on an exchange. the successful prediction of a stock's future price could yield significant profit. developed by using python, machine learning, deep learning and yahoo finance dataset.  3. doret-elfaleh ecommerce: a website that enable saudi arabia people to buy doret-elfaleh marble products using this site easily. developed by using python (django)  4. bone-x: a machine learning project that can recognize to the fracture or crack of bone. developed by using python, machine learning, deep learning and kaggle bone dataset.  5. youtube downloader: a program that helps student to download full course from youtube just passing playlist url and help ordinary people to download any video too. developed by using python  6. python translator: a program that helps student to translate text from one language to another. it used for long text. developed by using python  7. pdf reader (e-book): a program that convert pdf files to audio book to help blind people to read books like un-blind people. developed by using python  8. house price prediction: a machine learning project can predict the price of a house which include physical conditions, concept, and location. developed by using python, machine learning and kaggle house dataset.  9. voice assistant: a machine learning project that uses voice recognition, language processing algorithms, and voice synthesis to listen to specific voice commands and return relevant information or perform specific functions as requested by the user. developed by using python, pyttsx3, speechrecognition, machine learning and creating dataset as json file.      10. fake news detection: a machine learning project that classify fake news and real news by training model to real news dataset and fake news dataset. developed by using python, machine learning and kaggle fake news dataset  11. plants diseases detection: a machine learning project that can analysis plant leaf to recognize it and classify it to diseased or non-diseased leaf using cnn machine learning classification technique with a desired accuracy compared to other state of the art method. developed by using python, machine learning, deep learning, computer vision and kaggle plants diseases images dataset.  12.cv analysis: a machine learning project that can convert cv formatted in pdf or word to text. it can make a review for cv's and recommend job based on skills founded in cv and recommend some courses aim to his/her job to help on improve. developed by using python, machine learning, deep learning, computer vision and kaggle job requirements in linked|_jin dataset.  13. pavilion tech: a website for a startup programming company in use. to show their products and technologies. developed by using python  14. lecture summarization: a website for making a summary for lectures based on text, pdf, word files, ppt files, and videos using natural language processing and machine learning algorithms. the platform provides users with a summary of the main points in the content they upload. using machine learning and deep learning technology for making model. and java for making website. developed by using python  15. sign language translation: a website for detection sign language and converting it into voice using machine learning and deep learning technology for making model. developed by using python  16. mcv controller site: a website for detection driver behavior during driving and make alert to him / his if he or she busy during driving and record this data in database the owner of this site can show all these detections on dashboard and visualize this car on map using google api. to make this i use machine learning and deep learning technology for making model. developed by using python  17. atec courses site: a website to help student to study online under supervised obour academy and follow all student during study. developed by using python and django  18. text correction site: a website for correction wrong text and get all similar words using machine learning and deep learning technology for making model. developed by using python and django      19. baba-voss e-restaurant website : a web-based application that allows customers to view and order food from a restaurant online. the application has a user-friendly interface that includes features such as menu items, online ordering, and payment processing. url https://www.babavoss.site/  20. movie recommendation website : a website that recommends movies to users based on their preferences and past viewing history. the website uses collaborative filtering techniques and machine learning algorithms to suggest relevant movies to users.  21.1_dr skin cancer detection : a machine learning-based web application that uses deep learning models to detect skin cancer. the application allows users to upload an image of their skin and get a diagnosis of whether it's cancerous or not.  22. islamic website : a web-based platform that provides users with information on islamic teachings, traditions, and practices. the platform includes features such as articles, videos, and a forum for discussions.  23. electro cars ecommerce website : an online marketplace that allows users to buy and sell electric cars. the platform includes features such as a search function, user accounts, and payment processing.  e arabic (mother language) e english (very good)  huawei in artificial intelligence, udacity in web full stack, fwd udacity in web full stack  linked-in in javascript, linked-in in python, icdl, coursera in data structure, coursera in python, hacker rank in python, data science  ¢ date of birth: 10/12/1998 * nationality: egyptian * military status: exempted  ¢ marital status: engaged     \n"
     ]
    }
   ],
   "source": [
    "text = text.replace(\"\\n\",\" \")\n",
    "text = text.replace(\"[^a-zA-Z0-9]\", \" \");  \n",
    "re.sub('\\W+','', text)\n",
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f501f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = {}\n",
    "indices = []\n",
    "keys = []\n",
    "for key in Keywords:\n",
    "    try:\n",
    "        content[key] = text[text.index(key) + len(key):]\n",
    "        indices.append(text.index(key))\n",
    "        keys.append(key)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45f73c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['skills', 'summary']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped_lists = zip(indices, keys)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "sorted_pairs\n",
    "\n",
    "tuples = zip(*sorted_pairs)\n",
    "indices, keys = [ list(tuple) for tuple in  tuples]\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a949745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = []\n",
    "for idx in range(len(indices)):\n",
    "    if idx != len(indices)-1:\n",
    "        content.append(text[indices[idx]: indices[idx+1]])\n",
    "    else:\n",
    "        content.append(text[indices[idx]: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a042fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(indices)):\n",
    "    parsed_content[keys[i]] = content[i]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d232ffb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skills to improve company that i will work in, keeping learning modern information technology and improve my position in company.  2017 — 2021 bs in computer science form, the faculty of computer and informatics, zagazig  university, graduation project: stock market predictor using machine learning. project grade: excellent  e programming languages: python, c++, java , javascript  e al techniques: machine learning, deep learning , computer vision  e al framework: pytorch, scikit-learn, tensorflow.  e database: mysql, oracle, postgres, mongo db  e front-end: html5, css3, bootstrap  e back-end: django, flask  e other technology: os, linux, data structure , algorithms , github , rest-api , aws, microservices  e soft skill: communication, empathy , patience , open-minded , adaptability , critical thinking , creativity , confidence , teamwork and collaboration , eagar to learn , time management , work under pressure , ability to learn quickly and work as a part of team.      1. job board: a website employers use to advertise their available positions to qualified job seekers.  while employees can search for new opportunities, employers can fill vacancies with knowledgeable workers. developed by using python (django).  2. stock market predictor: a machine learning project that act of trying to determine the future value of a company stock or other financial instrument traded on an exchange. the successful prediction of a stock's future price could yield significant profit. developed by using python, machine learning, deep learning and yahoo finance dataset.  3. doret-elfaleh ecommerce: a website that enable saudi arabia people to buy doret-elfaleh marble products using this site easily. developed by using python (django)  4. bone-x: a machine learning project that can recognize to the fracture or crack of bone. developed by using python, machine learning, deep learning and kaggle bone dataset.  5. youtube downloader: a program that helps student to download full course from youtube just passing playlist url and help ordinary people to download any video too. developed by using python  6. python translator: a program that helps student to translate text from one language to another. it used for long text. developed by using python  7. pdf reader (e-book): a program that convert pdf files to audio book to help blind people to read books like un-blind people. developed by using python  8. house price prediction: a machine learning project can predict the price of a house which include physical conditions, concept, and location. developed by using python, machine learning and kaggle house dataset.  9. voice assistant: a machine learning project that uses voice recognition, language processing algorithms, and voice synthesis to listen to specific voice commands and return relevant information or perform specific functions as requested by the user. developed by using python, pyttsx3, speechrecognition, machine learning and creating dataset as json file.      10. fake news detection: a machine learning project that classify fake news and real news by training model to real news dataset and fake news dataset. developed by using python, machine learning and kaggle fake news dataset  11. plants diseases detection: a machine learning project that can analysis plant leaf to recognize it and classify it to diseased or non-diseased leaf using cnn machine learning classification technique with a desired accuracy compared to other state of the art method. developed by using python, machine learning, deep learning, computer vision and kaggle plants diseases images dataset.  12.cv analysis: a machine learning project that can convert cv formatted in pdf or word to text. it can make a review for cv's and recommend job based on skills founded in cv and recommend some courses aim to his/her job to help on improve. developed by using python, machine learning, deep learning, computer vision and kaggle job requirements in linked|_jin dataset.  13. pavilion tech: a website for a startup programming company in use. to show their products and technologies. developed by using python  14. lecture summarization: a website for making a \n"
     ]
    }
   ],
   "source": [
    "all_skills = parsed_content['skills']\n",
    "print(all_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc903e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"Parsed_Resume.json\", \"w\") as outfile:\n",
    "    json.dump(parsed_content, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62449ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"E-mail\": [\n",
      "        \"karimaboelazm6@gmail.com\",\n",
      "        \"20912017100480@fci.zu.edu.eg\"\n",
      "    ],\n",
      "    \"Phone number\": [\n",
      "        \"+201278789685\"\n",
      "    ],\n",
      "    \"Name\": \"Karim Mohammed Aboelazm\",\n",
      "    \"skills\": \"skills to improve company that i will work in, keeping learning modern information technology and improve my position in company.  2017 \\u2014 2021 bs in computer science form, the faculty of computer and informatics, zagazig  university, graduation project: stock market predictor using machine learning. project grade: excellent  e programming languages: python, c++, java , javascript  e al techniques: machine learning, deep learning , computer vision  e al framework: pytorch, scikit-learn, tensorflow.  e database: mysql, oracle, postgres, mongo db  e front-end: html5, css3, bootstrap  e back-end: django, flask  e other technology: os, linux, data structure , algorithms , github , rest-api , aws, microservices  e soft skill: communication, empathy , patience , open-minded , adaptability , critical thinking , creativity , confidence , teamwork and collaboration , eagar to learn , time management , work under pressure , ability to learn quickly and work as a part of team.      1. job board: a website employers use to advertise their available positions to qualified job seekers.  while employees can search for new opportunities, employers can fill vacancies with knowledgeable workers. developed by using python (django).  2. stock market predictor: a machine learning project that act of trying to determine the future value of a company stock or other financial instrument traded on an exchange. the successful prediction of a stock's future price could yield significant profit. developed by using python, machine learning, deep learning and yahoo finance dataset.  3. doret-elfaleh ecommerce: a website that enable saudi arabia people to buy doret-elfaleh marble products using this site easily. developed by using python (django)  4. bone-x: a machine learning project that can recognize to the fracture or crack of bone. developed by using python, machine learning, deep learning and kaggle bone dataset.  5. youtube downloader: a program that helps student to download full course from youtube just passing playlist url and help ordinary people to download any video too. developed by using python  6. python translator: a program that helps student to translate text from one language to another. it used for long text. developed by using python  7. pdf reader (e-book): a program that convert pdf files to audio book to help blind people to read books like un-blind people. developed by using python  8. house price prediction: a machine learning project can predict the price of a house which include physical conditions, concept, and location. developed by using python, machine learning and kaggle house dataset.  9. voice assistant: a machine learning project that uses voice recognition, language processing algorithms, and voice synthesis to listen to specific voice commands and return relevant information or perform specific functions as requested by the user. developed by using python, pyttsx3, speechrecognition, machine learning and creating dataset as json file.      10. fake news detection: a machine learning project that classify fake news and real news by training model to real news dataset and fake news dataset. developed by using python, machine learning and kaggle fake news dataset  11. plants diseases detection: a machine learning project that can analysis plant leaf to recognize it and classify it to diseased or non-diseased leaf using cnn machine learning classification technique with a desired accuracy compared to other state of the art method. developed by using python, machine learning, deep learning, computer vision and kaggle plants diseases images dataset.  12.cv analysis: a machine learning project that can convert cv formatted in pdf or word to text. it can make a review for cv's and recommend job based on skills founded in cv and recommend some courses aim to his/her job to help on improve. developed by using python, machine learning, deep learning, computer vision and kaggle job requirements in linked|_jin dataset.  13. pavilion tech: a website for a startup programming company in use. to show their products and technologies. developed by using python  14. lecture summarization: a website for making a \",\n",
      "    \"summary\": \"summary for lectures based on text, pdf, word files, ppt files, and videos using natural language processing and machine learning algorithms. the platform provides users with a summary of the main points in the content they upload. using machine learning and deep learning technology for making model. and java for making website. developed by using python  15. sign language translation: a website for detection sign language and converting it into voice using machine learning and deep learning technology for making model. developed by using python  16. mcv controller site: a website for detection driver behavior during driving and make alert to him / his if he or she busy during driving and record this data in database the owner of this site can show all these detections on dashboard and visualize this car on map using google api. to make this i use machine learning and deep learning technology for making model. developed by using python  17. atec courses site: a website to help student to study online under supervised obour academy and follow all student during study. developed by using python and django  18. text correction site: a website for correction wrong text and get all similar words using machine learning and deep learning technology for making model. developed by using python and django      19. baba-voss e-restaurant website : a web-based application that allows customers to view and order food from a restaurant online. the application has a user-friendly interface that includes features such as menu items, online ordering, and payment processing. url https://www.babavoss.site/  20. movie recommendation website : a website that recommends movies to users based on their preferences and past viewing history. the website uses collaborative filtering techniques and machine learning algorithms to suggest relevant movies to users.  21.1_dr skin cancer detection : a machine learning-based web application that uses deep learning models to detect skin cancer. the application allows users to upload an image of their skin and get a diagnosis of whether it's cancerous or not.  22. islamic website : a web-based platform that provides users with information on islamic teachings, traditions, and practices. the platform includes features such as articles, videos, and a forum for discussions.  23. electro cars ecommerce website : an online marketplace that allows users to buy and sell electric cars. the platform includes features such as a search function, user accounts, and payment processing.  e arabic (mother language) e english (very good)  huawei in artificial intelligence, udacity in web full stack, fwd udacity in web full stack  linked-in in javascript, linked-in in python, icdl, coursera in data structure, coursera in python, hacker rank in python, data science  \\u00a2 date of birth: 10/12/1998 * nationality: egyptian * military status: exempted  \\u00a2 marital status: engaged     \"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "a_file = open(\"Parsed_Resume.json\", \"r\")\n",
    "a_json = json.load(a_file)\n",
    "pretty_json = json.dumps(a_json, indent=4)\n",
    "a_file.close()\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fc9ed08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No email address found.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "parsed_content = {}\n",
    "\n",
    "def get_email_addresses(string):\n",
    "    r = re.compile(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', re.UNICODE)\n",
    "    return r.findall(string)\n",
    "\n",
    "text = \"karimaboelazm6é@gmail.com\"\n",
    "email = get_email_addresses(text)\n",
    "if email:\n",
    "    cleaned_email = email[0]  # Assuming there's only one email address found\n",
    "    print(cleaned_email)\n",
    "    parsed_content['E-mail'] = cleaned_email\n",
    "else:\n",
    "    print(\"No email address found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7c7d0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'karimaboelazm6@gmail.com'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_english(char):\n",
    "    return ord(char) < 128\n",
    "\n",
    "# Example string\n",
    "text = \"karimaboelazm6é@gmail.com\"\n",
    "new_text = ''\n",
    "for char in text:\n",
    "    if is_english(char):\n",
    "        new_text += char\n",
    "new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5015ced0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m extracted_sections\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Extract each section\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m cv_sections \u001b[38;5;241m=\u001b[39m \u001b[43mextract_section\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msection_headings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Convert the dictionary to a list of tuples for easier access\u001b[39;00m\n\u001b[0;32m     34\u001b[0m cv_sections_list \u001b[38;5;241m=\u001b[39m [(heading, content) \u001b[38;5;28;01mfor\u001b[39;00m heading, content \u001b[38;5;129;01min\u001b[39;00m cv_sections\u001b[38;5;241m.\u001b[39mitems()]\n",
      "Cell \u001b[1;32mIn[17], line 26\u001b[0m, in \u001b[0;36mextract_section\u001b[1;34m(text, section_headings)\u001b[0m\n\u001b[0;32m     24\u001b[0m         section_content \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(section_headings[i])[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m         section_content \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msection_headings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(section_headings[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     27\u001b[0m     extracted_sections[section_headings[i]] \u001b[38;5;241m=\u001b[39m section_content\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m extracted_sections\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "\n",
    "section_headings = [\n",
    "    \"CONTACT\",\n",
    "    \"EDUCATION\",\n",
    "    \"SKILLS\",\n",
    "    \"CERTIFICATIONS\",\n",
    "    \"SUMMARY\",\n",
    "    \"WORK EXPERIENCE\",\n",
    "    \"LANGUAGES\",\n",
    "    \"PERSONAL INFORMATION\",\n",
    "    \"PROJECTS\"\n",
    "]\n",
    "\n",
    "cv_sections = {}\n",
    "\n",
    "# Function to extract each section\n",
    "def extract_section(text, section_headings):\n",
    "    extracted_sections = {}\n",
    "    for i in range(len(section_headings)):\n",
    "        if i == len(section_headings) - 1:\n",
    "            section_content = text.split(section_headings[i])[1].strip()\n",
    "        else:\n",
    "            section_content = text.split(section_headings[i])[1].split(section_headings[i+1])[0].strip()\n",
    "        extracted_sections[section_headings[i]] = section_content\n",
    "    return extracted_sections\n",
    "\n",
    "# Extract each section\n",
    "cv_sections = extract_section(text, section_headings)\n",
    "\n",
    "# Convert the dictionary to a list of tuples for easier access\n",
    "cv_sections_list = [(heading, content) for heading, content in cv_sections.items()]\n",
    "\n",
    "# Print the list of sections\n",
    "for heading, content in cv_sections_list:\n",
    "    print(f\"--- {heading} ---\")\n",
    "    print(content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3da6901c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: karimaboelazm6@gmail.com Phone: +201278789685 Belbeis - Sharqia Egypt Linked-in: https://www.linkedin.com/in/karim- mohamed-aboelazm-3717001b3/ https://github.com/karim- aboelazm/\n"
     ]
    }
   ],
   "source": [
    "def clean_contact_info(contact_info):\n",
    "    # Remove any non-ASCII characters\n",
    "    cleaned_contact_info = ''.join(char for char in contact_info if ord(char) < 128)\n",
    "    \n",
    "    # Replace special characters with appropriate separators\n",
    "    cleaned_contact_info = cleaned_contact_info.replace(\"Db) \", \"Name: \")\n",
    "    cleaned_contact_info = cleaned_contact_info.replace(\"&, \", \"Phone: \")\n",
    "    cleaned_contact_info = cleaned_contact_info.replace(\"© \", \"Address: \")\n",
    "    cleaned_contact_info = cleaned_contact_info.replace(\"fa \", \"Linked-in: \")\n",
    "#     cleaned_contact_info = cleaned_contact_info.replace(\"https://github.com/karim-aboelazm/\", \"Github: \")\n",
    "    \n",
    "    # Remove any leading or trailing whitespace\n",
    "    cleaned_contact_info = cleaned_contact_info.strip()\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_contact_info = re.sub(r'\\s+', ' ', cleaned_contact_info)\n",
    "    \n",
    "    return cleaned_contact_info\n",
    "print(clean_contact_info(cv_sections_list[0][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
